{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69aae9f-03a3-4169-ae3e-e99f81e3e519",
   "metadata": {},
   "source": [
    "# Data Analytics - Module I Chapters 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834dde3c-30de-4f77-ac17-871aeb695e62",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5503f3e-fe4f-47f2-8bc4-cac33bfd1c5c",
   "metadata": {},
   "source": [
    "Data Cleaning involves identifying and rectifying errors, inconsistencies, and inaccuracies within the dataset. By eliminating missing values, outliers, and redundant information, data quality is enhanced, leading to more accurate and reliable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59b90d-fe4d-4f75-88d6-fa2a898a664d",
   "metadata": {},
   "source": [
    "### Handling Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71baa96a-da42-4a12-802e-10617ed4a265",
   "metadata": {},
   "source": [
    "Missing values in a dataset can hinder analysis and modeling. Pandas provides functions to handle missing values, such as  **fillna()**, which allows us to fill ***NaN*** values with a specific value or method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec77051-48c4-4e1a-aa77-7924324b805c",
   "metadata": {},
   "source": [
    "Let's first start by importing our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a672e8-ec35-40cc-80c8-53bc5456ca4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import pandas and numpy libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded1384-6e75-4ce5-85ee-fbf066212fdb",
   "metadata": {},
   "source": [
    "Now, let's practice filling ***NaN*** values using **fillna()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ea1a2e-44bb-4ef6-b819-e73e9afd4427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe before filling missing values:\n",
      "      A   B\n",
      "0  1.0  10\n",
      "1  2.0  20\n",
      "2  NaN  30\n",
      "3  4.0  40\n",
      "4  5.0  50\n",
      "Dataframe with missing values filled:\n",
      "      A   B\n",
      "0  1.0  10\n",
      "1  2.0  20\n",
      "2  0.0  30\n",
      "3  4.0  40\n",
      "4  5.0  50\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with missing values\n",
    "data = { \n",
    "     'A':[1, 2, np.nan, 4, 5],\n",
    "     'B':[10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Before filling missing value\n",
    "print(\"Dataframe before filling missing values:\\n\", df)\n",
    "\n",
    "# Filling missing values with 0\n",
    "df_filled = df.fillna(0)\n",
    "print(\"Dataframe with missing values filled:\\n\", df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98fe26-62ba-4291-8b12-2d1f7b2b2c7e",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d49cf-aaf4-41f7-8fc5-194ce1b48b12",
   "metadata": {},
   "source": [
    "Outliers are extreme values that can skew analysis and modeling results. Pandas can help us identify and handle outliers. In this example, we identify outliers using the **interquartile range (IQR)** method and remove them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b7a57-1998-402e-9beb-f1543ca54ce3",
   "metadata": {},
   "source": [
    "The **Interquartile Range (IQR)** is a measure of statistical dispersion, representing the range within which the middle 50% of the data lies. It is calculated as the difference between the 75th percentile (also called the third quartile, or Q3) and the 25th percentile (the first quartile, or Q1) of a dataset.\n",
    "\n",
    "The IQR is useful in identifying the spread of data, and it is commonly used to detect outliers. Values that are significantly lower than Q1 or significantly higher than Q3 are often considered outliers.\n",
    "\n",
    "Here's a breakdown of what the IQR represents in pandas and how to compute it:\n",
    "\n",
    "**What IQR Represents**\n",
    "-  Q1 (25th percentile): The value below which 25% of the data falls.\n",
    "-  Q3 (75th percentile): The value below which 75% of the data falls.\n",
    "-  IQR: The range between Q1 and Q3, calculated as IQR = Q3 - Q1.\n",
    "\n",
    "**How to Calculate IQR in pandas:**\n",
    "To calculate the IQR for a specific column in a pandas DataFrame, you can use the quantile method to get the 25th and 75th percentiles, and then subtract them to find the IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4230219-938b-48f7-a959-09df92495705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with outliers:\n",
      "    A    B\n",
      "0  1   10\n",
      "1  2   20\n",
      "2  3   30\n",
      "3  4  200\n",
      "4  5   50\n",
      "Dataframe with outliers removed:\n",
      "    A   B\n",
      "0  1  10\n",
      "1  2  20\n",
      "2  3  30\n",
      "4  5  50\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with outliers\n",
    "data = {\n",
    "        'A' : [1, 2, 3, 4, 5], \n",
    "        'B' : [10, 20, 30, 200, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Main Dataframe with Outliers\n",
    "print(\"DataFrame with outliers:\\n\", df)\n",
    "\n",
    "# Identifying and handling outliers\n",
    "q1 = df['B'].quantile(0.25)\n",
    "q3 = df['B'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5*iqr\n",
    "upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "df_no_outliers = df[(df['B'] >= lower_bound) & (df['B']<= upper_bound)]\n",
    "print(\"Dataframe with outliers removed:\\n\", df_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c99758-49a5-4f04-9d0c-ac1680856a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with outliers:\n",
      "    A    B\n",
      "0  1   10\n",
      "1  2   20\n",
      "2  3   30\n",
      "3  4  200\n",
      "4  5   50\n",
      "Dataframe with outliers removed:\n",
      "    A   B\n",
      "0  1  10\n",
      "1  2  20\n",
      "2  3  30\n",
      "4  5  50\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with outliers\n",
    "data = {\n",
    "        'A' : [1, 2, 3, 4, 5], \n",
    "        'B' : [10, 20, 30, 200, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Main Dataframe with Outliers\n",
    "print(\"DataFrame with outliers:\\n\", df)\n",
    "\n",
    "# Identifying and handling outliers\n",
    "q1 = df['B'].quantile(0.25)\n",
    "q3 = df['B'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5*iqr\n",
    "upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "df_no_outliers = df[(df['B'] >= lower_bound) & (df['B']<= upper_bound)]\n",
    "print(\"Dataframe with outliers removed:\\n\", df_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982fefd-3853-40be-b726-861467479fff",
   "metadata": {},
   "source": [
    "**Code Explanation**\n",
    "-  **q1** and **q3** are calculated using the **quantile()** function, representing the first and third quartiles of column ‘B’.\n",
    "-  **q1** represents the value below which 25% of the data lies. For column ‘B’, **q1** would be the median of the first half of the sorted values, which is 15.\n",
    "-  **q3** represents the value below which 75% of the data lies. For column ‘B’, **q3** would be the median of the second half of the sorted values, which is 50.\n",
    "-  **iqr** (Interquartile Range) is computed as the difference between **q3** and **q1**.\n",
    "-  **lower_bound** and **upper_bound** are calculated to define the thresholds beyond which data points are considered outliers. These bounds are defined as 1.5 times the IQR below q1 and above q3.\n",
    "-  The line **df_no_outliers = df[(df['B'] >= lower_bound) & (df['B'] <= upper_bound)]** filters the DataFrame to keep only the rows where the values in column ‘B’ fall within the acceptable range, effectively removing the outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30162c8-2de2-40fe-80e9-059c6f9825c8",
   "metadata": {},
   "source": [
    "### Dealing with Duplicate Data\n",
    "Duplicate data can lead to misleading analysis. Pandas provides functions to detect and remove duplicate rows. Here’s how we can do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a0f465-712e-461b-ab21-758ff097cf0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with duplicates:\n",
      "    A   B\n",
      "0  1  10\n",
      "1  2  20\n",
      "2  2  20\n",
      "3  3  30\n",
      "4  4  40\n",
      "5  4  40\n",
      "Duplicated rows:\n",
      "    A   B\n",
      "2  2  20\n",
      "5  4  40\n",
      "Dataframe without duplicated:\n",
      "    A   B\n",
      "0  1  10\n",
      "2  2  20\n",
      "3  3  30\n",
      "5  4  40\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with duplicate data\n",
    "data = {\n",
    "        'A': [1,2,2,3,4,4],\n",
    "        'B': [10,20,20,30,40,40]\n",
    "}\n",
    "duplicate_df = pd.DataFrame(data)\n",
    "\n",
    "# Main DataFrame with duplicate data\n",
    "print(\"Dataframe with duplicates:\\n\", duplicate_df)\n",
    "\n",
    "# Detecting and removing duplicated rows\n",
    "duplicated_rows = duplicate_df[duplicate_df.duplicated()]\n",
    "\n",
    "#Detecting and removing duplicated rows but keeping the first duplicate or the last duplicate\n",
    "deduplicated_df = duplicate_df.drop_duplicates(keep = 'last')\n",
    "\n",
    "print(\"Duplicated rows:\\n\", duplicated_rows)\n",
    "print(\"Dataframe without duplicated:\\n\", deduplicated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3e5cfe-5774-4955-b435-c500c81e0ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with duplicates:\n",
      "    A   B\n",
      "0  1  10\n",
      "1  2  20\n",
      "2  2  20\n",
      "3  3  30\n",
      "4  4  40\n",
      "5  4  40\n",
      "Duplicated rows:\n",
      "    A   B\n",
      "2  2  20\n",
      "5  4  40\n",
      "Dataframe without duplicated:\n",
      "    A   B\n",
      "0  1  10\n",
      "2  2  20\n",
      "3  3  30\n",
      "5  4  40\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with duplicate data\n",
    "data = {\n",
    "        'A': [1,2,2,3,4,4],\n",
    "        'B': [10,20,20,30,40,40]\n",
    "}\n",
    "duplicate_df = pd.DataFrame(data)\n",
    "\n",
    "# Main DataFrame with duplicate data\n",
    "print(\"Dataframe with duplicates:\\n\", duplicate_df)\n",
    "\n",
    "# Detecting and removing duplicated rows\n",
    "duplicated_rows = duplicate_df[duplicate_df.duplicated()]\n",
    "\n",
    "#Detecting and removing duplicated rows but keeping the first duplicate or the last duplicate\n",
    "deduplicated_df = duplicate_df.drop_duplicates(keep = 'last')\n",
    "\n",
    "print(\"Duplicated rows:\\n\", duplicated_rows)\n",
    "print(\"Dataframe without duplicated:\\n\", deduplicated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79085465-c240-43e9-abca-826c67c31a7f",
   "metadata": {},
   "source": [
    "### Data Reshaping\n",
    "Reshaping data is the process of transforming data from one format to another. In the context of data analysis and machine learning (ML), reshaping data often involves reorganizing it into a different structure that is better suited for analysis, visualization, or modeling. Reshaping can involve tasks such as pivoting, melting, stacking, unstacking, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d4205-2b6d-43ed-bdf8-ae31f69d461d",
   "metadata": {},
   "source": [
    "#### Wide to Long Format (Melting)\n",
    "In this transformation, we convert a dataset from a wide format (many columns) to a long format (fewer columns) by melting or unpivoting it. This is useful when we have variables stored as columns and we want to gather them into a single column.\n",
    "\n",
    "Melting data is useful for making it more suitable for analysis, especially when we want to compare or aggregate across different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb393e16-ed56-45a1-ac56-ad814798f288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original wide dataframe:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "2   3    78       92\n",
      "Long format dataframe:\n",
      "    ID  Subject  Score\n",
      "0   1     Math     90\n",
      "1   2     Math     85\n",
      "2   3     Math     78\n",
      "3   1  Science     75\n",
      "4   2  Science     88\n",
      "5   3  Science     92\n"
     ]
    }
   ],
   "source": [
    "# Creating a Wide DataFrame\n",
    "data = {\n",
    "        'ID': [1,2,3],\n",
    "        'Math': [90,85,78],\n",
    "        'Science':[75,88,92]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Main Wide DataFrame\n",
    "print(\"Original wide dataframe:\\n\", df)\n",
    "\n",
    "# Melting the DataFrame\n",
    "df_long = pd.melt(df, id_vars =['ID'], value_vars=['Math', 'Science'], var_name = 'Subject', value_name = 'Score')\n",
    "\n",
    "# After Melting the DataFrame\n",
    "print(\"Long format dataframe:\\n\", df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80194ee0-ee89-4f3a-9dbd-f707a7a79074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original wide dataframe:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "2   3    78       92\n",
      "Long format dataframe:\n",
      "    ID  Subject  Score\n",
      "0   1     Math     90\n",
      "1   2     Math     85\n",
      "2   3     Math     78\n",
      "3   1  Science     75\n",
      "4   2  Science     88\n",
      "5   3  Science     92\n"
     ]
    }
   ],
   "source": [
    "# Creating a Wide DataFrame\n",
    "data = {\n",
    "        'ID': [1,2,3],\n",
    "        'Math': [90,85,78],\n",
    "        'Science':[75,88,92]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Main Wide DataFrame\n",
    "print(\"Original wide dataframe:\\n\", df)\n",
    "\n",
    "# Melting the DataFrame\n",
    "df_long = pd.melt(df, id_vars =['ID'], value_vars=['Math', 'Science'], var_name = 'Subject', value_name = 'Score')\n",
    "\n",
    "# After Melting the DataFrame\n",
    "print(\"Long format dataframe:\\n\", df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c685f994-67e1-4bc8-a11b-a8d7b1c51895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original wide dataframe:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "2   3    78       92\n",
      "Long format dataframe:\n",
      "    ID  Subject  Score\n",
      "0   1     Math     90\n",
      "1   2     Math     85\n",
      "2   3     Math     78\n",
      "3   1  Science     75\n",
      "4   2  Science     88\n",
      "5   3  Science     92\n"
     ]
    }
   ],
   "source": [
    "# Creating a Wide DataFrame\n",
    "data = {\n",
    "        'ID': [1,2,3],\n",
    "        'Math': [90,85,78],\n",
    "        'Science':[75,88,92]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Main Wide DataFrame\n",
    "print(\"Original wide dataframe:\\n\", df)\n",
    "\n",
    "# Melting the DataFrame\n",
    "df_long = pd.melt(df, id_vars =['ID'], value_vars=['Math', 'Science'], var_name = 'Subject', value_name = 'Score')\n",
    "\n",
    "# After Melting the DataFrame\n",
    "print(\"Long format dataframe:\\n\", df_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf7b0e-276c-4462-9436-2bc545313fc5",
   "metadata": {},
   "source": [
    "**Code Explanation**\n",
    "-  The **pd.melt()** function is used to transform the *df* DataFrame from wide format to long format.\n",
    "-  **id_vars=['ID']** specifies that the ‘ID’ column should be kept as an identifier for each observation.\n",
    "-  **value_vars=['Math', 'Science']** specifies the columns (‘Math’ and ‘Science’) whose values will be “melted” or transformed into a single column.\n",
    "-  **var_name='Subject'** specifies the name of the new column that will store the subject names (‘Math’ and ‘Science’).\n",
    "-  **value_name='Score'** specifies the name of the new column that will store the scores for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e66fd-1dc1-4e9e-b878-c93cbfa71810",
   "metadata": {},
   "source": [
    "#### Long to Wide Format (Pivoting)\n",
    "This transformation involves converting a long-format dataset back into a wide format by pivoting or spreading the values.\n",
    "\n",
    "Pivoting is useful when we want to reshape data to make it easier to visualize or perform calculations on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dda1eb1-017d-49ad-bd69-27e5437c5815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original long dataframe:\n",
      "    ID  Subject  Score\n",
      "0   1     Math     90\n",
      "1   1  Science     75\n",
      "2   2     Math     85\n",
      "3   2  Science     88\n",
      "Wide format DataFrame:\n",
      " Subject  Math  Science\n",
      "ID                    \n",
      "1          90       75\n",
      "2          85       88\n"
     ]
    }
   ],
   "source": [
    "# Creating a Long DataFrame\n",
    "data = {\n",
    "        'ID': [1,1,2,2],\n",
    "        'Subject': ['Math','Science','Math','Science'],\n",
    "        'Score': [90,75,85,88]\n",
    "}\n",
    "df_long = pd.DataFrame(data)\n",
    "\n",
    "# Main Long DataFrame\n",
    "print(\"Original long dataframe:\\n\", df_long)\n",
    "\n",
    "# Pivoting the DataFrame\n",
    "df_wide = df_long.pivot(index='ID', columns = 'Subject', values = 'Score')\n",
    "print(\"Wide format DataFrame:\\n\", df_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17881c55-4323-4c3a-b45f-357ef2dc60b2",
   "metadata": {},
   "source": [
    "**Code Explanation** \n",
    "-  The **df_long.pivot()** function is used to transform the df_long DataFrame from a long format to a wide format.\n",
    "-  **index='ID'** specifies that the ‘ID’ column will be the index of the resulting pivoted DataFrame.\n",
    "-  **columns='Subject'** specifies that the unique values in the ‘Subject’ column will become the column headers of the pivoted DataFrame.\n",
    "-  **values='Score'** specifies that the values in the ‘Score’ column will be placed in the corresponding cells of the pivoted DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13195248-d6b9-49b8-b2a4-42447a84dffa",
   "metadata": {},
   "source": [
    "### Stacking and Unstacking\n",
    "Stacking involves converting columns into rows, and unstacking is the reverse process. These operations can be useful for creating hierarchical indexes and dealing with multi-level data.\n",
    "\n",
    "Stacking and unstacking can make data manipulation and analysis easier when dealing with multi-indexed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce57447-4ef1-44bf-b6c6-1a2f3d750303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "Stacked Dataframe:\n",
      " ID         \n",
      "1   Math       90\n",
      "    Science    75\n",
      "2   Math       85\n",
      "    Science    88\n",
      "dtype: int64\n",
      "Unstacked Dataframe:\n",
      "     Math  Science\n",
      "ID               \n",
      "1     90       75\n",
      "2     85       88\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID':[1,2],\n",
    "    'Math':[90,85],\n",
    "    'Science':[75,88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Set the DataFrame index using the ID column\n",
    "df.set_index('ID', inplace = True)\n",
    "\n",
    "# Doing Stacking and Unstacking\n",
    "stacked_df = df.stack()\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(\"Stacked Dataframe:\\n\", stacked_df)\n",
    "print(\"Unstacked Dataframe:\\n\", unstacked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30bed1e-dbeb-43b3-b860-f382882929b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "Stacked Dataframe:\n",
      " ID         \n",
      "1   Math       90\n",
      "    Science    75\n",
      "2   Math       85\n",
      "    Science    88\n",
      "dtype: int64\n",
      "Unstacked Dataframe:\n",
      "     Math  Science\n",
      "ID               \n",
      "1     90       75\n",
      "2     85       88\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID':[1,2],\n",
    "    'Math':[90,85],\n",
    "    'Science':[75,88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Set the DataFrame index using the ID column\n",
    "df.set_index('ID', inplace = True)\n",
    "\n",
    "# Doing Stacking and Unstacking\n",
    "stacked_df = df.stack()\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(\"Stacked Dataframe:\\n\", stacked_df)\n",
    "print(\"Unstacked Dataframe:\\n\", unstacked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9acf6f-9afe-4c98-a748-5b829271c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "Stacked Dataframe:\n",
      " ID         \n",
      "1   Math       90\n",
      "    Science    75\n",
      "2   Math       85\n",
      "    Science    88\n",
      "dtype: int64\n",
      "Unstacked Dataframe:\n",
      "     Math  Science\n",
      "ID               \n",
      "1     90       75\n",
      "2     85       88\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID':[1,2],\n",
    "    'Math':[90,85],\n",
    "    'Science':[75,88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Set the DataFrame index using the ID column\n",
    "df.set_index('ID', inplace = True)\n",
    "\n",
    "# Doing Stacking and Unstacking\n",
    "stacked_df = df.stack()\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(\"Stacked Dataframe:\\n\", stacked_df)\n",
    "print(\"Unstacked Dataframe:\\n\", unstacked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40aeb0b-22d4-4ee4-9542-ede5f25e7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    ID  Math  Science\n",
      "0   1    90       75\n",
      "1   2    85       88\n",
      "Stacked Dataframe:\n",
      " ID         \n",
      "1   Math       90\n",
      "    Science    75\n",
      "2   Math       85\n",
      "    Science    88\n",
      "dtype: int64\n",
      "Unstacked Dataframe:\n",
      "     Math  Science\n",
      "ID               \n",
      "1     90       75\n",
      "2     85       88\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID':[1,2],\n",
    "    'Math':[90,85],\n",
    "    'Science':[75,88]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Set the DataFrame index using the ID column\n",
    "df.set_index('ID', inplace = True)\n",
    "\n",
    "# Doing Stacking and Unstacking\n",
    "stacked_df = df.stack()\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(\"Stacked Dataframe:\\n\", stacked_df)\n",
    "print(\"Unstacked Dataframe:\\n\", unstacked_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c3fb5-b06a-4a59-8b3f-8bf9fd6fb488",
   "metadata": {},
   "source": [
    "### Handling Inconsistent Data and Standardizing\n",
    "Handling inconsistent data is a crucial step in data preprocessing to ensure the accuracy and reliability of our analysis or modeling. Inconsistent data refers to values that do not adhere to the expected format or constraints. This can include typos, varying representations, or unexpected values in categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23a7fe-0621-4aec-a2b8-c8453a8a6ad0",
   "metadata": {},
   "source": [
    "Suppose we have a dataset with a “Gender” column that contains variations of the categories “Male”, “Female”, and \"Other\". To handle inconsistencies, we can standardize the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a815113-5787-4e5c-87c9-3e5efd09a146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "    ID   Gender\n",
      "0   1     Male\n",
      "1   2   female\n",
      "2   3     mAle\n",
      "3   4   feMale\n",
      "4   5    Other\n",
      "5   6    oTHER\n",
      "Dataframe with consistent gender values:\n",
      "    ID  Gender\n",
      "0   1    Male\n",
      "1   2  Female\n",
      "2   3    Male\n",
      "3   4  Female\n",
      "4   5   Other\n",
      "5   6   Other\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "        'ID': [1,2,3,4,5,6],\n",
    "        'Gender': ['Male', ' female', 'mAle', 'feMale', 'Other', 'oTHER']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original Dataframe:\\n\", df)\n",
    "\n",
    "# Convert gender values to lowercase and standardize\n",
    "df['Gender'] = df['Gender'].str.lower().str.strip().replace({'male': 'Male', 'female' \n",
    "                                                             : 'Female', 'other':'Other'})\n",
    "print(\"Dataframe with consistent gender values:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34409bc1-ec41-4ba2-ab38-4372eb846ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "    ID   Gender\n",
      "0   1     Male\n",
      "1   2   female\n",
      "2   3     mAle\n",
      "3   4   feMale\n",
      "4   5    Other\n",
      "5   6    oTHER\n",
      "Dataframe with consistent gender values:\n",
      "    ID  Gender\n",
      "0   1    Male\n",
      "1   2  Female\n",
      "2   3    Male\n",
      "3   4  Female\n",
      "4   5   Other\n",
      "5   6   Other\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "        'ID': [1,2,3,4,5,6],\n",
    "        'Gender': ['Male', ' female', 'mAle', 'feMale', 'Other', 'oTHER']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original Dataframe:\\n\", df)\n",
    "\n",
    "# Convert gender values to lowercase and standardize\n",
    "df['Gender'] = df['Gender'].str.lower().str.strip().replace({'male': 'Male', 'female' \n",
    "                                                             : 'Female', 'other':'Other'})\n",
    "print(\"Dataframe with consistent gender values:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c80b98-9249-4cde-8e3b-cb982e6d1cc4",
   "metadata": {},
   "source": [
    "**Code Explanation**\n",
    "-  **df['Gender']** selects the ‘Gender’ column from the DataFrame.\n",
    "-  **.str.lower()** is a string method that converts all the values in the ‘Gender’ column to lowercase. This ensures that all variations of ‘male’ and ‘female’ are in lowercase, making the replacement consistent.\n",
    "-  **.replace({'male': 'Male', 'female': 'Female'})** is used to replace specific values in the ‘Gender’ column. Here, it’s specified that the value ‘male’ should be replaced with ‘Male’, the value ‘female’ should be replaced with ‘Female’, and the value ‘other’ should be replaced with ‘Other’.\n",
    "    - This replacement is case-insensitive due to the prior conversion to lowercase. For instance, ‘Male’ and ‘male’ will both be converted to ‘Male’.\n",
    "-  **.str.strip()** helps in removing leading and trailing whitespaces from a string. When dealing with textual data in Python, especially from external sources like files or user input, it's common to encounter unwanted leading or trailing whitespaces. These spaces might seem harmless, but they can significantly impact data analysis, leading to inconsistencies and errors.\n",
    "-  The updated ‘Gender’ column, after performing the lowercase conversion and replacements, is assigned back to the original ‘Gender’ column in the DataFrame. This effectively updates the values in the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54861d-1de0-4dfa-b4ff-dab900976899",
   "metadata": {},
   "source": [
    "Now, suppose we have a dataset with a “Color” column that contains various color names, including some inconsistent spellings and synonyms. We want to standardize these color names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0b697b-7466-4a08-ba7b-bc97249283b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "    ID    Color\n",
      "0   1      red\n",
      "1   2    green\n",
      "2   3     blue\n",
      "3   4    Green\n",
      "4   5  Reddish\n",
      "Dataframe with consistent color names:\n",
      "    ID  Color\n",
      "0   1    Red\n",
      "1   2  Green\n",
      "2   3   Blue\n",
      "3   4  Green\n",
      "4   5    Red\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID': [1,2,3,4,5],\n",
    "    'Color': ['red', 'green', 'blue', 'Green', 'Reddish']\n",
    "\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original Dataframe:\\n\", df)\n",
    "\n",
    "# Define a mapping for inconsistent color names to standard names\n",
    "color_mapping = {\n",
    "    'red' : 'Red',\n",
    "    'green' : 'Green',\n",
    "    'blue' : 'Blue',\n",
    "    'reddish': 'Red'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Color column\n",
    "df['Color'] = df['Color'].str.lower().map(color_mapping)\n",
    "\n",
    "print(\"Dataframe with consistent color names:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af527ebb-fa3a-4ba1-ad8c-6228ff3d0f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "    ID    Color\n",
      "0   1      red\n",
      "1   2    green\n",
      "2   3     blue\n",
      "3   4    Green\n",
      "4   5  Reddish\n",
      "Dataframe with consistent color names:\n",
      "    ID  Color\n",
      "0   1    Red\n",
      "1   2  Green\n",
      "2   3   Blue\n",
      "3   4  Green\n",
      "4   5    Red\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'ID': [1,2,3,4,5],\n",
    "    'Color': ['red', 'green', 'blue', 'Green', 'Reddish']\n",
    "\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Original DataFrame\n",
    "print(\"Original Dataframe:\\n\", df)\n",
    "\n",
    "# Define a mapping for inconsistent color names to standard names\n",
    "color_mapping = {\n",
    "    'red' : 'Red',\n",
    "    'green' : 'Green',\n",
    "    'blue' : 'Blue',\n",
    "    'reddish': 'Red'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Color column\n",
    "df['Color'] = df['Color'].str.lower().map(color_mapping)\n",
    "\n",
    "print(\"Dataframe with consistent color names:\\n\", df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
